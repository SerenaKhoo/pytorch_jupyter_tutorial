{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of content:\n",
    "* [Introduction and random notes](#first-bullet)\n",
    "    * Tensors are similar to Numpy's ndarrays --> but can be used on a GPU\n",
    "    * Tensors can be recreated from other tensors using the ``new_*`` method\n",
    "    \n",
    "* [Tensor operations](#second-bullet)\n",
    "    * There are multiple syntaxes for operations\n",
    "        * Syntax 1\n",
    "        * Syntax 2\n",
    "        * Syntax 3\n",
    "    * Any operation that mutates a tensor in-place is post-fixed with an ``_``. For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
    "\n",
    "* [Indexing the tensors](#third-bullet)\n",
    "    * \n",
    "        \n",
    "* [Resize or reshape tensor](#forth-bullet)\n",
    "    * ``*_view(*)`` function\n",
    "    * \n",
    "* [Getting value as a number](#fifth-bullet) \n",
    "    * ``*.item()`` function for 1 element tensor\n",
    "    * \n",
    "* [Converting to NumPy Array, vice versa](#sixth-bullet) \n",
    "    * \n",
    "    * \n",
    "* [Using of GPUs](#seventh-bullet)\n",
    "    * The ``to`` method moves the tensors onto any device (CPU, GPU...) \n",
    "    * Keeps track of the GPU and these are 0-indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and random notes <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a 5 x 3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  3.2622e-42,  0.0000e+00],\n",
      "        [ 0.0000e+00,  6.8608e+22,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3) # 5 sets of [with 3 elements]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8935,  0.7163,  0.7133],\n",
      "        [ 0.1363,  0.7012,  0.4815],\n",
      "        [ 0.2288,  0.6090,  0.8284],\n",
      "        [ 0.9810,  0.3910,  0.4508],\n",
      "        [ 0.9512,  0.6248,  0.1261]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct a matrix filled with zeros and of dtype float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3, dtype = torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct a matrix filled with ones and of dtype long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,3, dtype = torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructor a tensor directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5000,  3.0000],\n",
      "        [ 4.4000,  3.0000]])\n"
     ]
    }
   ],
   "source": [
    "x_new = torch.tensor([[5.5,3],[4.4,3]])\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a tensor based on existing tensor\n",
    "##### properties are reused unless stated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### new_* methods take in sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_new = x.new_ones(5,3, dtype = torch.double) # new_* methods take in sizes\n",
    "print(x_new)\n",
    "x_new = x.new_zeros(5,3, dtype = torch.double) # new_* methods take in sizes\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Override dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "tensor([[-1.1124, -0.0337,  1.2155],\n",
      "        [ 1.0124,  1.5540,  0.6375],\n",
      "        [-0.6025, -0.4342, -1.6678],\n",
      "        [-0.7746,  0.3888,  1.2857],\n",
      "        [-1.1158,  2.1800, -1.8758]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x_new = torch.randn_like(x, dtype = torch.float) # overrides the dtype and keep the size\n",
    "print(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get tensor size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size()) # This outputs a tuple hence it supports all tuple operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: \n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "y is: \n",
      "tensor([[ 0.4644,  0.5816,  0.7418],\n",
      "        [ 0.7620,  0.1233,  0.4731],\n",
      "        [ 0.2915,  0.4944,  0.0507],\n",
      "        [ 0.6650,  0.3723,  0.9225],\n",
      "        [ 0.8933,  0.9273,  0.5051]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "print(\"x is: \")\n",
    "print(x)\n",
    "print(\"y is: \")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Syntax 1 - x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4644,  1.5816,  1.7418],\n",
      "        [ 1.7620,  1.1233,  1.4731],\n",
      "        [ 1.2915,  1.4944,  1.0507],\n",
      "        [ 1.6650,  1.3723,  1.9225],\n",
      "        [ 1.8933,  1.9273,  1.5051]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f31979c69752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Element wise addition --> Hence must be same size?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "print(x + y) # Element wise addition --> Hence must be same size?\n",
    "\n",
    "print(torch.tensor([[2,3,4], [5,6,7]]) + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Syntax 2 - torch.add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4644,  1.5816,  1.7418],\n",
      "        [ 1.7620,  1.1233,  1.4731],\n",
      "        [ 1.2915,  1.4944,  1.0507],\n",
      "        [ 1.6650,  1.3723,  1.9225],\n",
      "        [ 1.8933,  1.9273,  1.5051]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Providing an output tensor as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "tensor([[ 1.4644,  1.5816,  1.7418],\n",
      "        [ 1.7620,  1.1233,  1.4731],\n",
      "        [ 1.2915,  1.4944,  1.0507],\n",
      "        [ 1.6650,  1.3723,  1.9225],\n",
      "        [ 1.8933,  1.9273,  1.5051]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5,3)\n",
    "print(\"result\")\n",
    "torch.add(x,y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Syntax 3 - y.add_(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This does in-place addition : Ie, the tensor at the front will be mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4644,  1.5816,  1.7418],\n",
      "        [ 1.7620,  1.1233,  1.4731],\n",
      "        [ 1.2915,  1.4944,  1.0507],\n",
      "        [ 1.6650,  1.3723,  1.9225],\n",
      "        [ 1.8933,  1.9273,  1.5051]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing the tensors <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is: \n",
      "tensor([[ 1.4644,  1.5816,  1.7418],\n",
      "        [ 1.7620,  1.1233,  1.4731],\n",
      "        [ 1.2915,  1.4944,  1.0507],\n",
      "        [ 1.6650,  1.3723,  1.9225],\n",
      "        [ 1.8933,  1.9273,  1.5051]])\n",
      "\n",
      "Getting the second column of all the rows: \n",
      "tensor([ 1.5816,  1.1233,  1.4944,  1.3723,  1.9273])\n"
     ]
    }
   ],
   "source": [
    "print(\"y is: \")\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "print(\"Getting the second column of all the rows: \")\n",
    "print(y[:, 1]) # All rows, second column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing or reshaping a tensor <a class=\"anchor\" id=\"forth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2721,  0.7503,  0.5569,  0.9770],\n",
      "        [ 0.2649,  0.9712,  0.5143,  0.9589],\n",
      "        [ 0.5193,  0.2695,  0.9072,  0.4709],\n",
      "        [ 0.3497,  0.6431,  0.6209,  0.3219]])\n",
      "\n",
      "tensor([ 0.2721,  0.7503,  0.5569,  0.9770,  0.2649,  0.9712,  0.5143,\n",
      "         0.9589,  0.5193,  0.2695,  0.9072,  0.4709,  0.3497,  0.6431,\n",
      "         0.6209,  0.3219])\n",
      "\n",
      "tensor([[ 0.2721,  0.7503,  0.5569,  0.9770,  0.2649,  0.9712,  0.5143,\n",
      "          0.9589],\n",
      "        [ 0.5193,  0.2695,  0.9072,  0.4709,  0.3497,  0.6431,  0.6209,\n",
      "          0.3219]])\n",
      "\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x_new2 = torch.rand(4,4) # 4 * 4\n",
    "print(x_new2)\n",
    "print()\n",
    "\n",
    "y_new2 = x_new2.view(16) # Compresses the tensor into a \"1-d array\"?\n",
    "print(y_new2)\n",
    "print()\n",
    "\n",
    "z_new2 = x_new2.view(-1,8) # size -1 means that we infer this from other dimensions --> since its 8, the first size is 16/8 = 2\n",
    "print(z_new2)\n",
    "print()\n",
    "\n",
    "print(x_new2.size(), y_new2.size(), z_new2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting element in tensor - ` .item() `<a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4049])\n",
      "0.4049144387245178\n",
      "\n",
      "tensor([[ 0.2679,  0.3810,  0.9067]])\n",
      "tensor(0.2679)\n",
      "0.2679094672203064\n",
      "\n",
      "tensor(0.3810)\n",
      "0.3809683918952942\n",
      "\n",
      "tensor(0.9067)\n",
      "0.9066909551620483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_new3 = torch.rand(1)\n",
    "print(x_new3)\n",
    "print(x_new3.item())\n",
    "print()\n",
    "\n",
    "x_new4 = torch.rand(1,3)\n",
    "print(x_new4)\n",
    "for tens in x_new4:\n",
    "    for ten in tens:\n",
    "        print(ten)\n",
    "        print(ten.item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting from tensor to NumPy Array, vice versa <a class=\"anchor\" id=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      "b\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.], dtype=torch.float64)\n",
      "\n",
      "c\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "print(\"a\")\n",
    "print(a)\n",
    "print()\n",
    "print(\"b\")\n",
    "print(b)\n",
    "print()\n",
    "\n",
    "c = b.numpy()\n",
    "print(\"c\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GPU ` .to` method <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "\n",
      "Devide y is on : cuda:0\n",
      "\n",
      "Before moving z to CPU\n",
      "tensor([ 1.2253,  1.4826,  1.9240,  1.3496,  1.4778], device='cuda:0')\n",
      "Device : cuda:0\n",
      "\n",
      "After moving z to CPU\n",
      "tensor([ 1.2253,  1.4826,  1.9240,  1.3496,  1.4778], dtype=torch.float64)\n",
      "Device : cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    \n",
    "    print(\"GPU is available\")\n",
    "    print()\n",
    "    \n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    print(\"Devide y is on : %s\"%(y.device))\n",
    "    print()\n",
    "    \n",
    "    x = x.to(device)                       \n",
    "    \n",
    "    z = x + y\n",
    "    \n",
    "    print(\"Before moving z to CPU\")\n",
    "    print(z)\n",
    "    print(\"Device : %s\"%z.device)\n",
    "    print()\n",
    "    \n",
    "    print(\"After moving z to CPU\")\n",
    "    z = z.to(\"cpu\", torch.double) # or just use strings ``.to(\"cuda\")``\n",
    "    print(z)       # ``.to`` can also change dtype together!\n",
    "    print(\"Device : %s\"%z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
