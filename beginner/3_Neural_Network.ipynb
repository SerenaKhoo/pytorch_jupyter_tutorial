{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # neural network module\n",
    "import torch.nn.functional as F # Function \n",
    "\n",
    "import torch.optim as optim # Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introduction and random notes](#notes)\n",
    "    * [Neutral Network module](#nn_module) \n",
    "        * Consists of \n",
    "            * layers \n",
    "            * forward method\n",
    "    * [Typical training process](#training_process)\n",
    "\n",
    "* [Define the network](#definition)\n",
    "* [Create network](#create_network)\n",
    "* [Run network](#run_network)\n",
    "    * [Random example](#random_example)\n",
    "* [Backwards Propagation](#back_prop)\n",
    "* [Loss Function](#loss)\n",
    "* [Update weights](#update_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction and random notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neutral Networds can be constructed using the torch.nn package <a class = \"anchor\" id=\"nn_module\"></a>\n",
    "    - Depends on autograd to define models and differentiate them \n",
    "\n",
    "An nn.Module contains: \n",
    "    - layers \n",
    "    - A method: \n",
    "        - forward(input) that returns the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: MNIST - A network that classifies digit images (Below shows LeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/beginner/mnist.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A typical training procedure <a class=\"anchor\" id=\"training_process\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the neural network that has some learnable parameters (or weights)\n",
    "2. Iterate over a dataset of inputs\n",
    "3. Process input through the network \n",
    "4. Compute the loss (how far is the output from being correct) \n",
    "5. Propagate gradients back into the network's parameters \n",
    "6. Update the weights of the network, typically using a simple update rule: \n",
    "    - Weight = weight - learning_rate * gradients (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network <a class=\"anchor\" id=\"definition\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be defining a CNN for our network: \n",
    "\n",
    "    self.conv1 = nn.Conv2d(1,6,5)\n",
    "\n",
    "    1 input channel, 6 output channels and 5 * 5 square convolution kernel \n",
    "\n",
    "    * 1 --> Only 1 input channel. Ie, greyscale. There can be 3 input channels when we take in RGB. 4 if we do RGBA (Alpha: Transparency). In short, there can be multiple input channels. Not limited to the above\n",
    "\n",
    "    * 6 -> 6 output channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module): # Our definition is the child of the parent class nn.module\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,6,5) # 1 input image channel, 6 output channels, 5*5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # 6 input channels\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x): # Does a max pooling over a (2,2) window \n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square, you can specify a single number \n",
    "        x = x.view(-1, self.num_flat_features(x)) # What is num_flat_features\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:] # Excepted the size to have 3 elements --> first is the number of channels, then width, then height.\n",
    "        num_features = 1 # Hence, we only look at the number of elements by doing channels * width * height \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network <a class=\"anchor\" id=\"create_network\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    stride=(1,1) : (x,y). Ie, how much to move in each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the network <a class=\"anchor\" id=\"run_network\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    We just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd.\n",
    "\n",
    "    We can use any of the Tensor operations in the foward function\n",
    "\n",
    "    The learnable paramters of a model are returned by: net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnable parameters of a model = 10\n",
      "\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(\"Learnable parameters of a model = %d\"%len(params))\n",
    "print()\n",
    "\n",
    "for i in range(len(params)):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying it with a random input <a class=\"anchor\" id=\"random_example\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note:\n",
    "    \n",
    "    torch.nn only supports inputs that are a mini-batch of samples and not a single sample\n",
    "    Hence, the input torch tensor is 4d --> [nSamples, nChannels, Height, Width]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.2829,  1.6497, -1.1925,  ..., -0.3277, -0.8164, -0.2679],\n",
      "          [-0.7825,  0.0575, -0.4530,  ...,  1.2262,  0.5073, -1.2832],\n",
      "          [-0.9226,  1.9950,  1.2180,  ...,  1.6844,  0.5414, -0.0612],\n",
      "          ...,\n",
      "          [ 0.8068, -0.1023,  0.5239,  ..., -1.4450,  0.0538, -0.7288],\n",
      "          [ 0.5715,  0.6349, -0.6024,  ...,  0.0426,  0.3723, -1.1822],\n",
      "          [-0.5468,  0.3463,  0.6148,  ...,  1.1758,  0.3162, -1.9371]]]])\n",
      "\n",
      "tensor([[ 0.0956,  0.1485,  0.0533, -0.0361,  0.0605,  0.0712, -0.0277,\n",
      "         -0.1027,  0.1241,  0.0266]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,32,32) # 1 batch, 1 image with 32 * 32 \n",
    "print(input)\n",
    "print()\n",
    "\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # Clear the buffer at each batch \n",
    "out.backward(torch.rand(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function <a class=\"anchor\" id=\"loss\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0956,  0.1485,  0.0533, -0.0361,  0.0605,  0.0712, -0.0277,\n",
      "         -0.1027,  0.1241,  0.0266]])\n",
      "Before: \n",
      "tensor([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.])\n",
      "\n",
      "After: \n",
      "tensor([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]])\n",
      "\n",
      "tensor(38.2061)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "print(output)\n",
    "\n",
    "target = torch.arange(1,11) # ie, range from 0 to 10 \n",
    "print(\"Before: \")\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "target = target.view(1, -1) # For it to be [[]] instead of []\n",
    "print(\"After: \")\n",
    "print(target)\n",
    "print()\n",
    "\n",
    "criterion = nn.MSELoss() # Setting our criterion to be MSE\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop <a class=\"anchor\" id=\"back_prop\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we follow loss in the backward direction, using its .grad_fn attribute, you will see a graph of computations that looks like this: \n",
    "    \n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "\n",
    "The following illustrates this graph of computations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000018E4A2A6F28>\n",
      "<AddmmBackward object at 0x0000018E4A2A6080>\n",
      "<ExpandBackward object at 0x0000018E4A2A6F28>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear function \n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, \n",
    "    \n",
    "    So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Tensors in the graph that has requires_grad=True will have their .grad Tensor accumulated with the gradient.\n",
    "    \n",
    "    To backpropagate the error all we have to do is to loss.backward(). You need to clear the existing gradients though, else gradients will be accumulated to existing gradients.\n",
    "\n",
    "    Now we shall call loss.backward(), and have a look at conv1â€™s bias gradients before and after the backward.\n",
    "    \n",
    "    To do so, we can call net.conv1(named by us).bias.grad. Alternatively to look at the gradient of the weights, we can do: \n",
    "    net.conv1.weight.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([ 0.,  0.,  0.,  0.,  0.,  0.])\n",
      "\n",
      "conv1.weight.grad before backward\n",
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]]])\n",
      "\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0981,  0.0451, -0.0318, -0.1263, -0.0685,  0.0768])\n",
      "\n",
      "conv1.weight.grad before backward\n",
      "tensor([[[[ 0.0277,  0.0151, -0.0913, -0.0468,  0.0277],\n",
      "          [ 0.0135, -0.0445,  0.0842,  0.0579, -0.1148],\n",
      "          [-0.1920, -0.0477,  0.0090, -0.1013,  0.0105],\n",
      "          [ 0.1014,  0.0314,  0.0045,  0.0315, -0.0956],\n",
      "          [ 0.0297,  0.1221,  0.1052,  0.1229,  0.0855]]],\n",
      "\n",
      "\n",
      "        [[[-0.0772, -0.1099, -0.0200, -0.0497,  0.0035],\n",
      "          [-0.0214, -0.0414,  0.0155, -0.0274,  0.0711],\n",
      "          [-0.1364, -0.0131,  0.0362, -0.0110, -0.1318],\n",
      "          [ 0.0083,  0.1819, -0.0605, -0.0327,  0.0304],\n",
      "          [-0.0679, -0.0624,  0.0137,  0.0226,  0.0101]]],\n",
      "\n",
      "\n",
      "        [[[-0.0558,  0.0399, -0.0122, -0.0127, -0.0170],\n",
      "          [ 0.0481, -0.0563, -0.0654,  0.0775, -0.1092],\n",
      "          [-0.0221, -0.1030, -0.0772, -0.0028, -0.0978],\n",
      "          [ 0.0640, -0.1729, -0.0950, -0.0208, -0.0625],\n",
      "          [ 0.0506,  0.0700,  0.0184,  0.0832, -0.0198]]],\n",
      "\n",
      "\n",
      "        [[[-0.1393, -0.0290,  0.0281, -0.0180, -0.1008],\n",
      "          [-0.2234,  0.1116,  0.1514, -0.0187, -0.0885],\n",
      "          [-0.0469, -0.0553, -0.0165, -0.0086, -0.0016],\n",
      "          [-0.0294,  0.0440,  0.0705, -0.1094, -0.1015],\n",
      "          [ 0.0226,  0.1602,  0.0113, -0.0592,  0.0513]]],\n",
      "\n",
      "\n",
      "        [[[-0.1315, -0.0177,  0.0491, -0.0478,  0.0273],\n",
      "          [-0.0668,  0.0118,  0.0444,  0.0660,  0.0953],\n",
      "          [ 0.0717,  0.1540, -0.1543,  0.1428,  0.0337],\n",
      "          [ 0.0514, -0.1172, -0.1173, -0.0329,  0.0217],\n",
      "          [ 0.0955, -0.1369,  0.0677,  0.1184, -0.1184]]],\n",
      "\n",
      "\n",
      "        [[[-0.0734,  0.0561,  0.0569,  0.0348, -0.0734],\n",
      "          [-0.0684, -0.0557, -0.0759, -0.0467,  0.0448],\n",
      "          [ 0.0219, -0.1057, -0.0498, -0.0641,  0.0565],\n",
      "          [-0.1031, -0.0892, -0.0049, -0.0018, -0.0156],\n",
      "          [ 0.1039, -0.0364,  0.0486, -0.0548, -0.0714]]]])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "print()\n",
    "print(\"conv1.weight.grad before backward\")\n",
    "print(net.conv1.weight.grad)\n",
    "print()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)\n",
    "print()\n",
    "print(\"conv1.weight.grad before backward\")\n",
    "print(net.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the weights <a class=\"anchor\" id=\"update_weights\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n",
    "    \n",
    "    weight = weight - learning_rate * gradient\n",
    "    \n",
    "We can use the torch.optim that implements all these methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr = 0.01) # Learning rate = 0.01\n",
    "\n",
    "# To update the weights, we can do the following: \n",
    "optimizer.zero_grad()\n",
    "output = net(input)\n",
    "loss = criterion(output, target) # We have placed the criterion to be MSE Loss \n",
    "loss.backward() # To do the backprop, to get the gradient WRT loss \n",
    "optimizer.step() # Update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
